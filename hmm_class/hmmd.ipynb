{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_normalized(d1, d2):\n",
    "    x = np.random.random((d1, d2))\n",
    "    return x / x.sum(axis=1, keepdims = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, M):\n",
    "        self.M = M # number of hidden states\n",
    "    \n",
    "    def fit(self, X, max_iter = 30):\n",
    "#         np.random.seed(123)\n",
    "        # train the HMM model using the Baum-Welch algorithm\n",
    "        # a specific instance of the expectation-maximization algorithm\n",
    "\n",
    "        # determine V, the vocabulary size\n",
    "        # assume observables are already integers from 0..V-1\n",
    "        # X is a jagged array of observed sequences\n",
    "        \n",
    "        V = max(max(x) for x in X) + 1 # number of possible observations: from 0 to V-1\n",
    "        N = len(X) # number of training samples\n",
    "        \n",
    "        self.pi = np.ones(self.M) / self.M # initial probability of being in some state\n",
    "        self.A = random_normalized(self.M, self.M) # transition probability between states\n",
    "        self.B = random_normalized(self.M, V) # probability of observation given state\n",
    "        \n",
    "        print(\"initial A: {}\".format(self.A))\n",
    "        print(\"initial B: {}\".format(self.B))\n",
    "        \n",
    "        costs = []\n",
    "        \n",
    "        for it in xrange(max_iter):\n",
    "            if it % 10 == 0:\n",
    "                print(\"it: {}\".format(it))\n",
    "            \n",
    "            alphas = []\n",
    "            betas = []\n",
    "            \n",
    "            P = np.zeros(N) # probability of each sequence\n",
    "            \n",
    "            for n in xrange(N):\n",
    "                x = X[n]\n",
    "                T = len(x) # observation duration\n",
    "                \n",
    "                alpha = np.zeros((T, self.M))\n",
    "                alpha[0] = self.pi * self.B[:, x[0]]\n",
    "                \n",
    "                for t in xrange(1, T):\n",
    "                    alpha[t] = alpha[t-1].dot(self.A) * self.B[:, x[t]]\n",
    "                \n",
    "                P[n] = alpha[-1].sum()\n",
    "                alphas.append(alpha)\n",
    "                \n",
    "                \n",
    "                beta = np.zeros((T, self.M))\n",
    "                beta[-1] = 1\n",
    "                for t in xrange(T-2, -1, -1):\n",
    "                    beta[t] = self.A.dot(self.B[:, x[t+1]] * beta[t+1])\n",
    "                    \n",
    "                betas.append(beta)\n",
    "            \n",
    "            \n",
    "            assert(np.all(P>0))\n",
    "            cost = np.sum(np.log(P))\n",
    "            costs.append(cost)\n",
    "            \n",
    "            \n",
    "            # now re-estimate pi, A, B\n",
    "            self.pi = np.sum((alphas[n][0] * betas[n][0]) / P[n] for n in xrange(N) ) / N\n",
    "            \n",
    "            den1 = np.zeros((self.M, 1))\n",
    "            den2 = np.zeros((self.M, 1))\n",
    "            \n",
    "            a_num = 0\n",
    "            b_num = 0\n",
    "            \n",
    "            \n",
    "            for n in xrange(N):\n",
    "                x = X[n]\n",
    "                T = len(x) # observation duration\n",
    "                \n",
    "                den1 += (alphas[n][:-1] * betas[n][:-1]).sum(axis=0, keepdims = True).T / P[n]\n",
    "                den2 += (alphas[n] * betas[n]).sum(axis=0, keepdims = True).T / P[n]\n",
    "                \n",
    "                # numerator for A\n",
    "                a_num_n = np.zeros((self.M, self.M))\n",
    "                for i in xrange(self.M):\n",
    "                    for j in xrange(self.M):\n",
    "                        for t in xrange(T-1):\n",
    "                            a_num_n[i,j] += alphas[n][t,i] * self.A[i,j] * self.B[j, x[t+1]] * betas[n][t+1,j]\n",
    "                            \n",
    "                a_num += a_num_n / P[n]\n",
    "            \n",
    "                # numerator for B\n",
    "                b_num_n = np.zeros((self.M, V))\n",
    "                for i in xrange(self.M):\n",
    "                    for t in xrange(T):\n",
    "                        b_num_n[i, x[t]] += alphas[n][t,i] * betas[n][t,i]\n",
    "                                \n",
    "                b_num += b_num_n / P[n]\n",
    "                \n",
    "            self.A = a_num / den1\n",
    "            self.B = b_num / den2\n",
    "            \n",
    "        print(\"A: {}\".format(self.A))\n",
    "        print(\"B: {}\".format(self.B))\n",
    "        print(\"pi: {}\".format(self.pi))\n",
    "        \n",
    "        plt.plot(costs)\n",
    "        plt.show()\n",
    "        \n",
    "    def likelihood(self, x):\n",
    "        # returns P(x | model)\n",
    "        # using the forward part of the forward-backward algorithm\n",
    "        T = len(x) # observation duration\n",
    "                \n",
    "        alpha = np.zeros((T, self.M))\n",
    "        alpha[0] = self.pi * self.B[:, x[0]]\n",
    "        \n",
    "        for t in xrange(1, T):\n",
    "            alpha[t] = alpha[t-1].dot(self.A) * self.B[:, x[t]]\n",
    "\n",
    "        return alpha[-1].sum()\n",
    "    \n",
    "    def likelihood_multi(self, X):\n",
    "        return np.array([self.likelihood(x) for x in X])\n",
    "    \n",
    "    def log_likelihood_multi(self, X):\n",
    "        return np.log(self.likelihood_multi(X))\n",
    "    \n",
    "    def get_state_sequence(self, x):\n",
    "        # returns the most likely state sequence given observed sequence x\n",
    "        # using the Viterbi algorithm\n",
    "        \n",
    "        T = len(x)\n",
    "        \n",
    "        delta = np.zeros((T, self.M))\n",
    "        psi = np.zeros((T, self.M))\n",
    "        \n",
    "        delta[0] = self.pi * self.B[:, x[0]]\n",
    "        \n",
    "        for t in xrange(1,T):\n",
    "            for j in xrange(self.M):\n",
    "                delta[t, j] = np.max(delta[t-1]*self.A[:,j]) * self.B[j, x[t]]\n",
    "                psi[t, j] = np.argmax(delta[t-1]*self.A[:,j])\n",
    "                \n",
    "        #backtrack\n",
    "        states = np.zeros(T, dtype=np.int32)\n",
    "        \n",
    "        states[T-1] = np.argmax(delta[T-1])\n",
    "        \n",
    "        for t in xrange(T-2, -1, -1):\n",
    "            states[t] = psi[t+1, states[t+1]]\n",
    "        \n",
    "        return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_coin():\n",
    "    X = []\n",
    "    for line in open('coin_data.txt'):\n",
    "        # 1 for H, 0 for T\n",
    "        x = [1 if e == 'H' else 0 for e in line.strip()]\n",
    "        X.append(x)\n",
    "        \n",
    "    hmm = HMM(2)\n",
    "    hmm.fit(X)\n",
    "    \n",
    "    L = hmm.log_likelihood_multi(X).sum()\n",
    "    \n",
    "    print(\"Log-Likelihood with fitted parameters: {}\".format(L))\n",
    "    \n",
    "    print(\"Best state sequence for {} :\".format(X[0]))\n",
    "    print(hmm.get_state_sequence(X[0]))\n",
    "    \n",
    "    hmm.pi = np.array([0.5, 0.5])\n",
    "    hmm.A = np.array([[0.1, 0.9], [0.8, 0.2]])\n",
    "    hmm.B = np.array([[0.6, 0.4], [0.3, 0.7]])\n",
    "    \n",
    "    TL = hmm.log_likelihood_multi(X).sum()\n",
    "    print(\"Log-Likelihood with actual parameters: {}\".format(TL))\n",
    "    \n",
    "    print(\"Best state sequence for {} :\".format(X[0]))\n",
    "    print(hmm.get_state_sequence(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial A: [[ 0.46602537  0.53397463]\n",
      " [ 0.57693427  0.42306573]]\n",
      "initial B: [[ 0.32305693  0.67694307]\n",
      " [ 0.65294756  0.34705244]]\n",
      "it: 0\n",
      "it: 10\n",
      "it: 20\n",
      "it: 30\n",
      "it: 40\n",
      "it: 50\n",
      "it: 60\n",
      "it: 70\n",
      "it: 80\n",
      "it: 90\n",
      "A: [[ 0.2943616   0.7056384 ]\n",
      " [ 0.68651349  0.31348651]]\n",
      "B: [[ 0.28732758  0.71267242]\n",
      " [ 0.78737139  0.21262861]]\n",
      "pi: [ 0.5228034  0.4771966]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD/CAYAAADxL6FlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw5ACAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6d4c07b850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Likelihood with fitted parameters: -1026.96434159\n",
      "Best state sequence for [0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1] :\n",
      "[1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 1 0]\n",
      "Log-Likelihood with actual parameters: -1059.72291603\n",
      "Best state sequence for [0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1] :\n",
      "[0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "fit_coin()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
